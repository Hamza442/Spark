{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71236096",
   "metadata": {},
   "source": [
    "# Initialize SparkSession & Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93cf9533",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "sc=spark.sparkContext\n",
    "\n",
    "from pyspark.sql.functions import regexp_replace,length,col\n",
    "from pyspark.sql.types import StringType"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6710ef7",
   "metadata": {},
   "source": [
    "# Milestone-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c1dd333",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath=\"D:/UpWork/PySpark/\"\n",
    "text_file = sc.textFile(filepath+\"pg100.txt\")\n",
    "\n",
    "# word count without pre-processing\n",
    "textfile_rdd = text_file.flatMap(lambda line: line.split(\" \")) \\\n",
    "                            .map(lambda word: (word, 1)) \\\n",
    "                           .reduceByKey(lambda x, y: x + y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "857f509d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------+\n",
      "|Word| Count|\n",
      "+----+------+\n",
      "|    |506610|\n",
      "| the| 23407|\n",
      "|   I| 19540|\n",
      "| and| 18358|\n",
      "|  to| 15682|\n",
      "|  of| 15649|\n",
      "|   a| 12586|\n",
      "|  my| 10825|\n",
      "|  in|  9633|\n",
      "| you|  9129|\n",
      "|  is|  7874|\n",
      "|that|  7543|\n",
      "| And|  7068|\n",
      "| not|  6967|\n",
      "|with|  6771|\n",
      "| his|  6218|\n",
      "|  be|  6017|\n",
      "|your|  6016|\n",
      "| for|  5629|\n",
      "|have|  5236|\n",
      "+----+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# creating a dataframe to show results\n",
    "wordcount_df=textfile_rdd.toDF([\"Word\",\"Count\"])\n",
    "wordcount_df=wordcount_df.sort(wordcount_df[\"Count\"].desc())\n",
    "wordcount_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e1e69bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# writing output to csv file\n",
    "wordcount_df.coalesce(1)\\\n",
    ".write.mode(\"overwrite\")\\\n",
    ".option('header', 'true') \\\n",
    ".option(\"mapreduce.fileoutputcommitter.marksuccessfuljobs\",\"false\")\\\n",
    ".csv(filepath+\"milestone_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cec82c2",
   "metadata": {},
   "source": [
    "# Milestone-2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef617d8",
   "metadata": {},
   "source": [
    "transform all words to lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3f472625",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lower_clean_str(x):\n",
    "    punc='!\"#$%&\\'()*+,/:;<=>?@[\\\\]^_`{|}~-'\n",
    "    lowercased_str = x.lower()\n",
    "    for ch in punc:\n",
    "        lowercased_str = lowercased_str.replace(ch, '')\n",
    "    return lowercased_str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95cf53b",
   "metadata": {},
   "source": [
    "remove whitespaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a0c3624e",
   "metadata": {},
   "outputs": [],
   "source": [
    "shakespeare_rdd = text_file.map(lower_clean_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e06b4a56",
   "metadata": {},
   "source": [
    "# separate the words in all lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7ae64116",
   "metadata": {},
   "outputs": [],
   "source": [
    "shakespeare_rdd=shakespeare_rdd.flatMap(lambda satir: satir.split(\" \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9fa46e1",
   "metadata": {},
   "source": [
    "# exclude whitespaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4cd5f9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "shakespeare_rdd = shakespeare_rdd.filter(lambda x:x!='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "37492572",
   "metadata": {},
   "outputs": [],
   "source": [
    "shakespeare_rdd_list=shakespeare_rdd.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553179c1",
   "metadata": {},
   "source": [
    "# removing numerice values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "989becbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "word=[]\n",
    "num=[]\n",
    "for element in shakespeare_rdd_list:\n",
    "    if element.isdigit():\n",
    "        num.append(element)\n",
    "    else:\n",
    "        word.append(element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "45d0da93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|      value|\n",
      "+-----------+\n",
      "|        the|\n",
      "|    project|\n",
      "|  gutenberg|\n",
      "|      ebook|\n",
      "|         of|\n",
      "|        the|\n",
      "|   complete|\n",
      "|      works|\n",
      "|         of|\n",
      "|    william|\n",
      "|shakespeare|\n",
      "|         by|\n",
      "|    william|\n",
      "|shakespeare|\n",
      "|       this|\n",
      "|      ebook|\n",
      "|         is|\n",
      "|        for|\n",
      "|        the|\n",
      "|        use|\n",
      "+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# convert to data frame for futer processing\n",
    "df = spark.createDataFrame(word, StringType())\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a06e7bca",
   "metadata": {},
   "source": [
    "# Transforming non-alphabetic characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c1e5d3f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+------+\n",
      "|      value|      clean|length|\n",
      "+-----------+-----------+------+\n",
      "|        the|        the|     3|\n",
      "|    project|    project|     7|\n",
      "|  gutenberg|  gutenberg|     9|\n",
      "|      ebook|      ebook|     5|\n",
      "|         of|         of|     2|\n",
      "|        the|        the|     3|\n",
      "|   complete|   complete|     8|\n",
      "|      works|      works|     5|\n",
      "|         of|         of|     2|\n",
      "|    william|    william|     7|\n",
      "|shakespeare|shakespeare|    11|\n",
      "|         by|         by|     2|\n",
      "|    william|    william|     7|\n",
      "|shakespeare|shakespeare|    11|\n",
      "|       this|       this|     4|\n",
      "|      ebook|      ebook|     5|\n",
      "|         is|         is|     2|\n",
      "|        for|        for|     3|\n",
      "|        the|        the|     3|\n",
      "|        use|        use|     3|\n",
      "+-----------+-----------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_df=df.select(\"value\",regexp_replace(\"value\",'[^A-Za-z]','').alias(\"clean\"))\n",
    "new_df=new_df.select(\"value\",\"clean\",length(\"clean\").alias(\"length\"))\n",
    "new_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e09f09c",
   "metadata": {},
   "source": [
    "# Removing single alphabetic character "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6c427c25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|      clean|\n",
      "+-----------+\n",
      "|        the|\n",
      "|    project|\n",
      "|  gutenberg|\n",
      "|      ebook|\n",
      "|         of|\n",
      "|        the|\n",
      "|   complete|\n",
      "|      works|\n",
      "|         of|\n",
      "|    william|\n",
      "|shakespeare|\n",
      "|         by|\n",
      "|    william|\n",
      "|shakespeare|\n",
      "|       this|\n",
      "|      ebook|\n",
      "|         is|\n",
      "|        for|\n",
      "|        the|\n",
      "|        use|\n",
      "+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cleaned_df=new_df.filter(col(\"length\")!=1)\n",
    "final_df=cleaned_df.drop(\"value\",\"length\")\n",
    "final_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb53e01b",
   "metadata": {},
   "source": [
    "# Getting second letter for each word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "99c9bc18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|second_letter|\n",
      "+-------------+\n",
      "|            h|\n",
      "|            r|\n",
      "|            u|\n",
      "|            b|\n",
      "|            f|\n",
      "|            h|\n",
      "|            o|\n",
      "|            o|\n",
      "|            f|\n",
      "|            i|\n",
      "|            h|\n",
      "|            y|\n",
      "|            i|\n",
      "|            h|\n",
      "|            h|\n",
      "|            b|\n",
      "|            s|\n",
      "|            o|\n",
      "|            h|\n",
      "|            s|\n",
      "+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_df_sc=final_df.select(final_df[\"clean\"].substr(2,1).alias(\"second_letter\"))\n",
    "final_df_sc.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ac7fce8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd_final=final_df_sc.rdd.flatMap(lambda x:x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7f26134c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd_final = rdd_final.filter(lambda x:x!='')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a202ba29",
   "metadata": {},
   "source": [
    "# word occuernce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "45ca8494",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_processed = rdd_final.flatMap(lambda line: line.split(\" \")) \\\n",
    "                            .map(lambda word: (word, 1)) \\\n",
    "                           .reduceByKey(lambda x, y: x + y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fa431e5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------+\n",
      "|Word| Count|\n",
      "+----+------+\n",
      "|   o|169803|\n",
      "|   h|117259|\n",
      "|   e|112429|\n",
      "|   a| 86992|\n",
      "|   i| 81464|\n",
      "|   n| 66069|\n",
      "|   r| 45644|\n",
      "|   u| 37584|\n",
      "|   f| 24603|\n",
      "|   l| 23268|\n",
      "|   s| 20763|\n",
      "|   y| 20683|\n",
      "|   t| 20426|\n",
      "|   p|  8763|\n",
      "|   w|  6111|\n",
      "|   m|  5245|\n",
      "|   c|  3802|\n",
      "|   x|  3614|\n",
      "|   v|  2759|\n",
      "|   g|  2316|\n",
      "+----+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_final=counts_processed.toDF([\"Word\",\"Count\"])\n",
    "df_final=df_final.sort(df_final[\"Count\"].desc())\n",
    "df_final.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d181a080",
   "metadata": {},
   "outputs": [],
   "source": [
    "# writing output to csv file\n",
    "df_final.coalesce(1)\\\n",
    ".write.mode(\"overwrite\")\\\n",
    ".option('header', 'true') \\\n",
    ".option(\"mapreduce.fileoutputcommitter.marksuccessfuljobs\",\"false\")\\\n",
    ".csv(filepath+\"milestone_2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c72bdfd1",
   "metadata": {},
   "source": [
    "# Suggestions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae46397",
   "metadata": {},
   "source": [
    "This is my suggestion and if you like it can,you can go with this approach as well.\n",
    "***Remove Stopwords***\n",
    "Stopwords are the English words which does not add much meaning to a sentence. They can safely be ignored without sacrificing the meaning of the sentence. For example, the words like the, he, have etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fc5f6002",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|      clean|\n",
      "+-----------+\n",
      "|        the|\n",
      "|    project|\n",
      "|  gutenberg|\n",
      "|      ebook|\n",
      "|         of|\n",
      "|        the|\n",
      "|   complete|\n",
      "|      works|\n",
      "|         of|\n",
      "|    william|\n",
      "|shakespeare|\n",
      "|         by|\n",
      "|    william|\n",
      "|shakespeare|\n",
      "|       this|\n",
      "|      ebook|\n",
      "|         is|\n",
      "|        for|\n",
      "|        the|\n",
      "|        use|\n",
      "+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_stg=cleaned_df.drop(\"value\",\"length\")\n",
    "df_stg.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cbbfab22",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_rdd=df_stg.rdd.flatMap(lambda x:x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea7541f0",
   "metadata": {},
   "source": [
    "# removing stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "64840a5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1a953b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stopwords =stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2dc676c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_rdd_final = new_rdd.filter(lambda x: x not in stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6078f45c",
   "metadata": {},
   "source": [
    "# Difference in counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c70daafb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "482662"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_rdd_final.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b332dd2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "864465"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_rdd.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4b56ef9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "words=new_rdd_final.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "93ccd331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+\n",
      "|       value|\n",
      "+------------+\n",
      "|     project|\n",
      "|   gutenberg|\n",
      "|       ebook|\n",
      "|    complete|\n",
      "|       works|\n",
      "|     william|\n",
      "| shakespeare|\n",
      "|     william|\n",
      "| shakespeare|\n",
      "|       ebook|\n",
      "|         use|\n",
      "|      anyone|\n",
      "|    anywhere|\n",
      "|        cost|\n",
      "|      almost|\n",
      "|restrictions|\n",
      "|  whatsoever|\n",
      "|         may|\n",
      "|        copy|\n",
      "|        give|\n",
      "+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataframe=spark.createDataFrame(words, StringType())\n",
    "\n",
    "dataframe.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e7d5fa0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|second_letter|\n",
      "+-------------+\n",
      "|            r|\n",
      "|            u|\n",
      "|            b|\n",
      "|            o|\n",
      "|            o|\n",
      "|            i|\n",
      "|            h|\n",
      "|            i|\n",
      "|            h|\n",
      "|            b|\n",
      "|            s|\n",
      "|            n|\n",
      "|            n|\n",
      "|            o|\n",
      "|            l|\n",
      "|            e|\n",
      "|            h|\n",
      "|            a|\n",
      "|            o|\n",
      "|            i|\n",
      "+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataframe_final=dataframe.select(dataframe[\"value\"].substr(2,1).alias(\"second_letter\"))\n",
    "dataframe_final.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d8a1a2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_rdd_final=dataframe_final.rdd.flatMap(lambda x:x)\n",
    "new_rdd_final = new_rdd_final.filter(lambda x:x!='')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "87ce9585",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_processed_new = new_rdd_final.flatMap(lambda line: line.split(\" \")) \\\n",
    "                            .map(lambda word: (word, 1)) \\\n",
    "                           .reduceByKey(lambda x, y: x + y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "665e69aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+\n",
      "|Word|Count|\n",
      "+----+-----+\n",
      "|   o|85692|\n",
      "|   e|76751|\n",
      "|   a|75197|\n",
      "|   i|54309|\n",
      "|   h|39436|\n",
      "|   r|35913|\n",
      "|   u|24696|\n",
      "|   n|20409|\n",
      "|   l|19364|\n",
      "|   t| 9222|\n",
      "|   p| 7691|\n",
      "|   w| 5340|\n",
      "|   s| 5172|\n",
      "|   c| 3802|\n",
      "|   x| 3614|\n",
      "|   y| 3210|\n",
      "|   m| 3077|\n",
      "|   v| 2592|\n",
      "|   d| 2145|\n",
      "|   f| 1910|\n",
      "+----+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataframe_final=counts_processed_new.toDF([\"Word\",\"Count\"])\n",
    "dataframe_final=dataframe_final.sort(dataframe_final[\"Count\"].desc())\n",
    "dataframe_final.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d557325a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
